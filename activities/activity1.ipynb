{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a67f85d-6cac-47aa-ab01-3bb1654d7099",
   "metadata": {},
   "source": [
    "###  Activity 1: All Possible Regressions\n",
    "\n",
    "This is a quick assignment.  I would expect it to only take a couple of hours to complete. The start of this notebook develops the example.  You will then parallelize the exammple using `joblib`. \n",
    "\n",
    "Run this on a machine that has at least 4 cores. Typically this is your laptop. The ugrad machines are also OK. Google Colab is not adequate. Fill out the requested cells toward the bottom of the notebook.\n",
    "\n",
    "**Due date**: September 16 1, 2022, 5:00 pm EDT.\n",
    "\n",
    "**Instructions for Submission**: Submit via Gradescope.\n",
    "\n",
    "#### Preparing the Environment\n",
    "\n",
    "You will need a couple of packages installed to make this work.  Stop your instance of jupyter lab and then run\n",
    "\n",
    "```\n",
    "conda install pandas pandoc\n",
    "jupyter lab\n",
    "```\n",
    "At this point, you should be ready to go.\n",
    "\n",
    "#### Example code\n",
    "\n",
    "This is a Python reimplementation of the Section 3.4. in _Matloff_, Parallel Computing for Data Science. It is based on data from https://www.kaggle.com/divan0/multiple-linear-regression. The notebook asks the question what combination of variables best predict the price of a house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9525a93-0b4e-4a25-bf87-d4335132cffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#importing dataset using panda\n",
    "dataset = pd.read_csv('../data/kc_house_data.csv')\n",
    "#to see what my dataset is comprised of\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad55ee-ba79-4673-b693-ebca04f1bb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the id and date column\n",
    "dataset = dataset.drop(['id','date'], axis = 1)\n",
    "\n",
    "# clean out NaN and inf values\n",
    "dataset = dataset[~dataset.isin([np.nan, np.inf, -np.inf]).any(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f724288c-e17e-46a4-939b-c5ec0fc34a3b",
   "metadata": {},
   "source": [
    "Let's first do a simple regression. How does square footage predict price? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd8b494-d600-4bc9-9af7-15bef7796fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = np.array(dataset.sqft_living)\n",
    "Y = np.array(dataset.price)\n",
    "\n",
    "# shape X into matrix of a single column\n",
    "X = X.reshape((X.shape[0],1))\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X,Y)\n",
    "r_sq = model.score(X,Y)\n",
    "print('coefficient of determination:', r_sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97519567-fe0a-439e-a7e7-d97e4d56dea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# scatter data\n",
    "plt.plot(X,Y,'o')\n",
    "# best fit line\n",
    "y_pred = model.intercept_ + model.coef_ * X\n",
    "plt.plot(X, y_pred, color='red', linewidth=3)\n",
    "\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c639cbb5-6bdd-4032-812a-5bf8e0174833",
   "metadata": {},
   "source": [
    "We see that there is a strong correlation between square footage and house price.  The coefficient of determination measures the strength of the correlation and varies between 0 (no correlation) and 1.0 (perfectly correlated)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2d9af2-3882-4c1d-9f58-038567ffd5ac",
   "metadata": {},
   "source": [
    "### Multiple Linear Regression\n",
    "\n",
    "Adding more variables often improves the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccb721f-db9f-4c58-ad3b-d7ed629791a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(dataset[['sqft_living','condition','yr_built']])\n",
    "Y = np.array(dataset.price)\n",
    "\n",
    "# shape X into matrix of a single column\n",
    "X = X.reshape((X.shape[0],3))\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X,Y)\n",
    "r_sq = model.score(X,Y)\n",
    "print('coefficient of determination:', r_sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e900ab88-873c-4290-9d99-723cef811c6d",
   "metadata": {},
   "source": [
    "but some variables are confounding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff60bd53-6ebc-4f13-8c78-5e81992aebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(dataset[['zipcode','floors','waterfront']])\n",
    "Y = np.array(dataset.price)\n",
    "\n",
    "# shape X into matrix of a single column\n",
    "X = X.reshape((X.shape[0],3))\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X,Y)\n",
    "r_sq = model.score(X,Y)\n",
    "print('coefficient of determination:', r_sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d948a45-a861-423a-b2ce-8fcf1bf976c3",
   "metadata": {},
   "source": [
    "This leads to a first parallel program.  What are the right set of variables? A brute force approach called _All Possible Regressions_ examines all combinations. So, let's build a big matrix that and we will regress on subsets.  We will look at all combinations of 1, 2, or 3 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615005bd-f622-43a0-a844-c32f11e2676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations, chain\n",
    "\n",
    "Y = np.array(dataset.price)\n",
    "X = np.array(dataset.drop(['price'], axis=1))\n",
    "\n",
    "## Let's choose all combinations of 1, 2, and 3 columns.\n",
    "col_idxs = np.array(range(X.shape[1]))\n",
    "combos = list(chain(combinations(col_idxs, 1), combinations(col_idxs, 2), combinations(col_idxs, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc919ff9-24aa-4a9b-a4ee-efc84f8b51d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "# do in a for loop (dumbest way)\n",
    "r_sq_best = 0.0\n",
    "for combo in combos:\n",
    "    Xp = X[:,combo]\n",
    "    model = model.fit(Xp,Y)\n",
    "    r_sq = model.score(Xp,Y)\n",
    "    if r_sq > r_sq_best:\n",
    "        r_sq_best = r_sq\n",
    "        combo_best = combo\n",
    "    \n",
    "print(r_sq_best, combo_best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603e45b6-80e4-4c6c-9a2f-1e8a728b1e5b",
   "metadata": {},
   "source": [
    "The outcome is kind of crazy. The fields are `sqft-living`, `view`, and `latitude`. Latitude is probably a somewhat accurate proxy for wealth in this area, e.g. N of town richer than south of town. But, this is the kind of outcome that would not translate to other regions, i.e. is likely specific to this data.  _Neat_.\n",
    "\n",
    "Back to performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8377d0-63a9-439c-be04-92d19f25e71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "model = LinearRegression()\n",
    "\n",
    "r_sq_best = 0.0\n",
    "for combo in combos:\n",
    "    Xp = X[:,combo]\n",
    "    model = model.fit(Xp,Y)\n",
    "    r_sq = model.score(Xp,Y)\n",
    "    if r_sq > r_sq_best:\n",
    "        r_sq_best = r_sq\n",
    "        combo_best = combo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8f2fb1-6df7-4902-9e5a-ed4ccfc231a1",
   "metadata": {},
   "source": [
    "Let's see if flattening the loop matters. Replace for loop with a list comprehension of all combination of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7993f4bd-6331-42f5-b909-31c6f1b659cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_sq_regression (combo):\n",
    "    Xp = X[:,combo]\n",
    "    model = LinearRegression()\n",
    "    model = model.fit(Xp,Y)\n",
    "    return model.score(Xp,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96184a66-012a-4068-a462-677fcafb2ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sq_list = [ (combo, r_sq_regression(combo)) for combo in combos ]\n",
    "r_sq_arr = np.array(r_sq_list, dtype=object)\n",
    "r_sq_idx = np.argmax(r_sq_arr[:,1])\n",
    "print(r_sq_arr[r_sq_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbf14c0-c47c-4b51-aed3-cde5f1b9af7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "r_sq_list = [ (combo, r_sq_regression(combo)) for combo in combos ]\n",
    "r_sq_arr = np.array(r_sq_list, dtype=object)\n",
    "r_sq_idx = np.argmax(r_sq_arr[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3298cb7-ab53-4a34-8442-883faa04a8ab",
   "metadata": {},
   "source": [
    "It didn't seem to help. But, this is a step toward parallelization.\n",
    "\n",
    "### Exercise (This is the assignment)\n",
    "\n",
    "1. Use `joblib.Parallel` and `joblib.delayed` to parallelize the computation of the calls to `r_sq_regression`. \n",
    "    1. In one cell, print the answer to verify that your parallel program is correct.\n",
    "    2. In another cell time the computation. What is the speedup at `n_jobs=4`?\n",
    "    3. Estimate the Amdahl number for this computation. Show your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1194559-1102-4978-bc80-a4911dddf37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO code for 1A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3643a3bb-383c-4da9-aa94-e2f35e9b67ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit \n",
    "# TODO code for 1B "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed98d844-2cb4-4760-928d-bc2511399d9d",
   "metadata": {},
   "source": [
    "**TODO Answer for 1B**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4d94a2-fb3d-4d04-a315-6c913e677fad",
   "metadata": {},
   "source": [
    "2. Use the batch size parameter to vary the number of tasks in each batch from 1,2,...128 @ n_jobs=4. You will need to look at the joblib documentation to read up about batch size.\n",
    "   1. Plot your results (use %timeit -o to capture output)\n",
    "   2. Model the problem as having two performance components: a fixed startup cost per batch ($C_B$) and perfect parallelism.  Estimate the batch startup cost (give a range).\n",
    "   3. Your answer to the batch startup costs should be noisy, i.e. there is not a consistent estimate for startup costs across all batch sizes. This indicates that a fixed startup cost per batch is not a good model. Consider other startup costs, such as skew, interference, and startup costs (per job). What do you think is a reasonable explanation for the inefficiency? What factors are possible?  Which factors can you eliminate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebbd6e8-16ae-4a89-bed8-05f10bda3f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for 2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b5cf1b-4914-4294-8077-844c16e8aabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# TODO plot for 2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b23ce8-19a3-4505-9904-f042ec73745e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for 2B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d662db6-2c99-45c2-a71b-a4482c454371",
   "metadata": {},
   "source": [
    "**TODO Answer for 2B**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b3cb77-8d34-4eab-bc1a-09fd8266a07f",
   "metadata": {},
   "source": [
    "3. Run the job with `prefer='threads'` and `prefer='processes'`. Given that `LinearRegression.fit()`. You do not need to vary batch size for this part.\n",
    "    1. Which is more efficient?  Why? Consider our discussion of parallel threads in python.\n",
    "    2. Can you conclude that `LinearRegression.fit()` does or does not release the GIL? Explain.\n",
    "\n",
    "_Note_: you can verify this conclusion by calling `LinearRegression.fit()` directly, rather than calling the wrapper functions `r_sq_regression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192d3aed-d2c7-45c8-83bd-83462fdc24bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b831431-437f-48e8-b24c-3952a8ab2ebf",
   "metadata": {},
   "source": [
    "**TODO Answer to 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e2c81e-aa2d-487e-bbce-f5c48ab45b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
