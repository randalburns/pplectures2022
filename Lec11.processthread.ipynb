{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OS Abstractions Processes and Threads\n",
    "\n",
    "From the Mattson textbook, we have the following concepts:\n",
    "* _Task_: sequence of instructions that operate as a group\n",
    "* Unit of execution (_UE_): process or a thread, the execution context for a task\n",
    "* Processing Element (_PE_): hardware element that runs the UE\n",
    "\n",
    "For OpenMP these were\n",
    "* _Task_ == Block invocation or loop iteration\n",
    "* _UE_ == Thread\n",
    "* _PE_ == Processor core\n",
    "\n",
    "But, we haven't formally defined _thread_.  So, let's look at Operating System abstractions.\n",
    "\n",
    "## Processes\n",
    "\n",
    "“A process is the operating system’s abstraction for a running program” (Bryant and O’Halloran, _Computer Systems_.)\n",
    "Processes “provide the illusion that the program is the only one running on the system.”\n",
    "* Each process appears:\n",
    "  * To have exclusive use of the hardware\n",
    "  * To execute instructions one after another without interruption\n",
    "* By definition, processes do not share memory\n",
    "\n",
    "The process abstraction allows for multiple serial programs to run concurrently and in parallel when parallel hardware is available.  Processes have their roots in [Time Sharing](https://en.wikipedia.org/wiki/Time-sharing) operating systems of the 1960s.\n",
    "\n",
    "Each process has a __context__: the information needed for the operating system to implement its abstraction.\n",
    "* Context is the per process state maintained by the OS\n",
    "  * Needed to suspend and resume processes\n",
    "  * Includes: program counter, register file, contents of memory\n",
    "\n",
    "In a _context switch_ an operating system transparently switches among the running processes.\n",
    "\n",
    "<img src=\"images/oscontext.png\" width=512 title=\"from Bryant and O'Halloran....I think\" />\n",
    "\n",
    "### Virtual Memory\n",
    "\n",
    "* As part of the abstraction, processes appear to have exclusive use of memory:\n",
    "  * It’s actually a virtual address space, because the addresses don’t correspond to HW addresses\n",
    "* Memory contains the state of a single program\n",
    "  * Code, data, heap, stack\n",
    "  * Memory mapped (shared) libraries\n",
    "  \n",
    " <img src=\"images/osvm.png\" width=384 title=\"from Bryant and O'Halloran....I think\" />\n",
    "\n",
    "  \n",
    "### Advantages and Disadvantages\n",
    "\n",
    "* No shared state!\n",
    "  * Applications that need to share state, must do so explicitly using inter-process communication (IPC)\n",
    "  * E.g. RPC, sockets, shmem (shared memory area). message passing\n",
    "  * All interfaces are clunky.\n",
    "* No shared state, means no dependencies\n",
    "  * Simple parallel programs\n",
    "  * Run the same program on lots of PEs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Threads\n",
    "\n",
    "A __thread__ is a concurrent execution unit within a process\n",
    "* Threads share memory (entire virtual address space)\n",
    "* Threads have their own, lightweigth context\n",
    "  * thread identifier, stack, registers, instruction pointer\n",
    "  * lighter than process (does not include contents of memory)\n",
    "  \n",
    "<img src=\"http://cocoadevcentral.com/articles/imgs/multi_thr_mem.png\" width=512 title=\"Thread Memory Layout\" />\n",
    "\n",
    "\n",
    "* Every process has at least one thread.\n",
    "  * we say the the process execution context is it's thread of execution\n",
    "  * processes may have many threads (the operating sytem schedules their concurrent/parallel execution)\n",
    "  \n",
    "<img src=\"http://www.cs.miami.edu/home/visser/Courses/CSC322-09S/Content/UNIXProgramming/Threads.JPG\" width=512 title=\"Thread Execution\" />\n",
    "\n",
    "### Advantages/Disadvantages of Threads\n",
    "\n",
    "Shared variables!\n",
    "* Easy communication between execution contexts\n",
    "  * Multiple threads coordinate their actions and share data through reading and writing shared variables\n",
    "* But, Hidden dependencies hard to debug\n",
    "  * Variables may be updated by other threads: change from serial mindset\n",
    "* OOP to the rescue\n",
    "  * Objects provide encapsulation in support of threading\n",
    "  * Classes control access to shared data via synchronization, volatile, and atomic language features \n",
    "  \n",
    "Design priniciples:  Map objects to threads.  All data encapsulated in the object is _thread private data_ (analagous to block local data in OpenMP).  All shared data is explicitly handed into objects (by reference) on construction.  Reads and writes to shared data needs to by _synchronized_. \n",
    "\n",
    "### Simulataneous Multi-Threading\n",
    "\n",
    "This is the concept of running multiple threads on each core at the same time.  It's based on the idea that cores actually have multiple (and heterogeneous) units that could (in principle) do different things at the same time.  \n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/27/Hyper-threaded_CPU.png/660px-Hyper-threaded_CPU.png\" width=256 title=\"Intel hyperthreading.\" />\n",
    "\n",
    "\n",
    "* Intel has _hyper-threading_ an SMT implementation (picture from Wikipedia above)\n",
    "  * Processor advertises 2 cores to operating system\n",
    "  * OS schedules two threads on a core at the same time\n",
    "  * Sometimes you get some speedup (rarely more than 130%)\n",
    "  \n",
    "The figure is somewhat confusing.  The front end reorders instructions based on data dependencies. The execution core shows the different processors units (e.g. 2 floating point units, load, store, load address, branch).  The takeaway is that different unit can conduct operations at the same time. Hyperthreading makes it so that the instructions can come from two threads.\n",
    "  \n",
    "The consequence is that when your computer says that it has $X$ cores, you achieve good speedup to $X/2$ cores...that happens on dedicate physical cores.  Then, you get worse speedup for $(X/2,X]$ because threads are sharing cores, and then no more speedup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
