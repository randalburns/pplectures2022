{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Data Parallel Frameworks\n",
    "\n",
    "We now turn to distributed data parallel frameworks.  The next section will take us through the evolution of Map/Reduce -> Hadoop! -> Spark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations of Dask: Why to use Spark!\n",
    "\n",
    "Dask is well integrated into the python ecosystem. This is the best and worst part of dask.  \n",
    "* Best:\n",
    "  * dask inherites the efficient implementations of the underlying libraries in NumPy and pandas.\n",
    "  * dask is easy to use for python programers\n",
    "* Worst\n",
    "  * dask is python and python is a serial and interpreted (not compiled) language\n",
    "  * inefficient for user-defined functions (they run in python)\n",
    "  * global shuffles are inefficient in dask\n",
    "  \n",
    "Shuffles are the key.  Map/reduce is about shuffling (sorting data by key). All systems that build on top of this paradigm inherit efficient shuffles in distributed memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dask Datatypes, Functions, and Operators\n",
    "\n",
    "Because Dask is a data parallel language, it's reasonable to categorize dask around the three major \"collections\" implemented:\n",
    "  * dask.array: a parallel NumPy array\n",
    "  * dask.dataframe: a parallel pandas dataframe\n",
    "  * dask.bag: inherited from Spark (and Pig).\n",
    "  \n",
    "So, arrays and dataframes make sense.  Where did this bag come from? Dask reports that \"It is similar to a parallel version of PyToolz or a Pythonic version of the PySpark RDD.\"\n",
    "\n",
    "### dask bags\n",
    "\n",
    "A dask bag or multiset is:\n",
    "  * unordered: cannot be indexed like an array\n",
    "  * not-unique: can have repeated entries\n",
    "  * contains arbitrary python objects\n",
    "  \n",
    "This makes it a **key/value** system\n",
    "  * key: identifier for a data object that can be evaluated for equality (and typically sorted)\n",
    "  * value: an uninterpreted _BLOB_ of data. The system can't unpack or operate on value data.  Although, user-defined functions can.\n",
    "  \n",
    "The dask guidance is to only use bags when absolutely needed and to convert to arrays or dataframes as soon as possible. Bags support the nested data structures typical of JSON, e.g. dictionaries that contain lists of lists.  The limitations are:\n",
    "  * bags only use the 'processes' scheduler and cannot share memory among the multiple cores of a node\n",
    "  * user-defined functions are inefficient when compared with pandas or numpy builtins \n",
    "\n",
    "Additionally, dask **strongly** encourages you to avoid <code>bag.groupby()</code>, because it requires a full shuffle (sort by key) of the data.\n",
    "\n",
    "**Conclusion**: dask bags are for computing user-defined functions on distributed data structures. But, these are not dask's strengths.  In this case, we will look to other engines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A brief history of data-parallel compute engines\n",
    "\n",
    "* Map/Reduce (2004): At Google, Jeff Dean and Sanjay Ghemawat outline the future of large-scale data processing\n",
    "  * <code>map()</code>: applies a user-defined function to a data partition and outputs a <code>key</code> used to identify objects in a class and a <code>value</code> that contains the data.\n",
    "  * <code>reduce()</code>: takes all items with the same key and applies a user-defined function that aggregates the data.\n",
    "  * This was the start of automatic parallelism (some disagree). The programmer writes two _pure_ functions and creates a computation that scales to thousands of nodes and TB of data.\n",
    "* Hadoop! (2006): open source implementation of map/reduce computing\n",
    "  * Credit to Doug Cutting and Mike Cafarella.\n",
    "  * Users write Java functions that execute at scale.\n",
    "  \n",
    "We now move out of the Google ecosystem. Google has continued to make important contributions that inform open-source.\n",
    "\n",
    "* Pig (2008): meta-programming for Hadoop!\n",
    "  * declarative constructs that compile to map/reduce programs\n",
    "  * uses the bag data type as an abstraction for key/value data \n",
    "* Hive (2010): SQL interface to Hadoop!\n",
    "  * SQL queries can be executed in two iterations of map/reduce\n",
    "  * Scalable data processing for those\n",
    "* Spark (2014): in-memory data for iterative programming in map/reduce\n",
    "  * built on the \"resilient distributed dataset\" which is a data-parallel partitioned multiset.\n",
    "  * executes programs on Hadoop!\n",
    "* Dask (2016?): \"pythonic\" version of Spark that eases programming for NumPy and pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "Guidance for dask:\n",
    "  * try to convert semi-structured data to dataframes as soon as possible\n",
    "  * try to use built-in functions whenever possible, they are optimized\n",
    "  \n",
    "Guidance for when and how to use Spark:\n",
    "  * for workloads that perform shuffles, Spark runs on top of the Hadoop! engine.\n",
    "  * for complex user-defined functions, but you must write them in Scala which compiles into java.\n",
    "\n",
    "Spark is a bigger, heavier ecosystem with a more complex distributed query optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
