{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA Architecture Evolution\n",
    "\n",
    "Turing <- Pascal <- Maxwell <- Kepler <- Fermi <- Tesla <- G70\n",
    "  * G70 is GeForce Series 7 2005\n",
    "\n",
    "\n",
    "<img src=\"https://devblogs.nvidia.com/wp-content/uploads/2018/09/image2.jpg\" width=768 />\n",
    "\n",
    "* 4,608 CUDA Cores\n",
    "  * 64 cores / SM\n",
    "* 672 GB/sec memory throughput\n",
    "* 6 MB L2 memory\n",
    "\n",
    "<img src=\"https://devblogs.nvidia.com/wp-content/uploads/2018/09/image11.jpg\" width=512 />\n",
    "\n",
    "Properties:\n",
    "  * 16.3 GFlops of double precision floating point\n",
    "  * 32.6 GFlops of single precisions floating point\n",
    "  * 16.3 TIPs of integer arithmetic\n",
    "  * Reduced precision tensor cores (INT8 and INT4)\n",
    "    * for ML workloads that can tolerate quantization\n",
    "\n",
    "And a die shot:\n",
    "\n",
    "<img src=\"https://www.servethehome.com/wp-content/uploads/2018/08/NVIDIA-Turing-Die-Shot.png\" width=512 />\n",
    "\n",
    "### Properties of CUDA (all architectures)\n",
    "\n",
    "* Fundamental unit is the CUDA core\n",
    "  * Integer arithmetic logic unit ALU \n",
    "  * Double-precision floating point FPU\n",
    "  * Fused multiply-add instruction Fully pipelined\n",
    "* CUDA cores are grouped into stream multiprocessors (SM)\n",
    "  * SMs run in SIMD lockstep\n",
    "* Observations\n",
    "  * High memory throughput (now 672 GB/s) c.f. 256 GB/S on Intel Skylake\n",
    "  * Little cache -- essentially useless\n",
    "\n",
    "### Programming Model\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/5/59/CUDA_processing_flow_%28En%29.PNG\" width=512 />\n",
    "\n",
    "* Transfer data to accelerator\n",
    "  * limited by PCIe speed, typically 8GB/s one way\n",
    "* Invoke remote computation\n",
    "* Extract result\n",
    "\n",
    "#### Consequences\n",
    "* For CUDA to be effective, the computation must be intense w.r.t. the data.\n",
    "  * 8 GB/s of transfer compared with 600 GB/s memory to processor\n",
    "  * _Must_ use data values multiple time\n",
    "* CUDA programs must be simple\n",
    "  * FP and integer arithmetic\n",
    "  * no cache hierarchy to support data reuse\n",
    "  * similarly no HW support for branching and speculation (more on this later).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recent Developments\n",
    "\n",
    "Changes that have made CUDA general purpose.\n",
    "* Double precision\n",
    "  * graphics cards were always single precision.  Why?\n",
    "* Memory system\n",
    "  * L1 cache per SM\n",
    "  * Global L2 cache\n",
    "  * ECC (error correcting memory)\n",
    "    * why does graphics not need ECC memory?\n",
    "* Concurrent kernel execution\n",
    "  * kernel is the name for a CUDA program\n",
    "  * used to be one kernel at a time\n",
    "\n",
    "<img src=\"./images/fermikernel.png\" width=512 />\n",
    "\n",
    "* Muliple-GPU interconnects\n",
    "  * fast data transfer among GPUs\n",
    "  * needed from ML training\n",
    "\n",
    "<img src=\"https://devblogs.nvidia.com/wp-content/uploads/2014/11/nvlink_configurability.png\" width=768 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So What??\n",
    "\n",
    "CUDA is delivering FLOPs faster, cheaper and at less power than CPUs.\n",
    "\n",
    "<img src=\"./images/cudacpimemory.png\" width=768 />\n",
    "\n",
    "GPUs are everywhere:\n",
    "\n",
    "    * on supercomputers as accelerators\n",
    "    * on laptops already because they have screens\n",
    "    * on phones (or architectures inspired by GPU principles) because of power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
