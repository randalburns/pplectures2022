{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serial to Parallel: OpenMP\n",
    "\n",
    "The simplest and most common parallel pattern is to take a serial program and convert it into a parallel program.\n",
    "\n",
    "* My code’s not running fast enough:\n",
    "  * Video: data delays produce jitter, stalls\n",
    "  * Web: page render time causes user loss, discomfort\n",
    "  * Batch processing, indexing, analysis not completing in time \n",
    "  * High-throughput finance: other models running faster and beating mine to a decision -> lose arbitrage opportunity\n",
    "* This leads to a natural software engineering process\n",
    "  * Profile code: find out what’s slow\n",
    "  * Parallelize slow part(s) only\n",
    "  * Migrate from serial implementation to parallel implementation\n",
    "* It's  not the best process\n",
    "  * Serial to parallel doesn’t produce the best designs\n",
    "  * Best parallel implementation may require a totally different design with no incremental refatoring from serial implementation\n",
    "* Just the easiest\n",
    "  * Compared to a clean-slate redesign\n",
    "\n",
    "### What is OpenMP\n",
    "\n",
    "Parallel programming environment (not language) for:\n",
    "* Master/slave and/or fork/join execution model\n",
    "* Loop parallelism patterns\n",
    "* Thread parallelism in shared-memory architectures\n",
    "But this doesn’t mean anything yet.\n",
    "\n",
    "It’s the simplest approach to parallelism\n",
    "* Write a serial program in a language that you know (C++ or Fortran)\n",
    "* Add directives to parallelize portions of the code\n",
    "* Get a parallel program that computes that exact same result (_serial to parallel equivalence_)\n",
    "\n",
    "What's the merit:\n",
    "* Incremental parallelism\n",
    "* Simple to Use\n",
    "* Portable (for the most part)\n",
    "\n",
    "Limitations:\n",
    "* DIfficult to manage memory usage\n",
    "* No distributed capabilities\n",
    "* No parallel I/O\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Block Parallelism\n",
    "\n",
    "The fundamental Principle in OpenMP is to parallelize a _block_ and run multiple instances of the block with parallel threads.\n",
    "\n",
    "__NoteBook__ <a href=\"openmp/blocks.ipynb\">Block Parallelism</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The OpenMP Toolchain\n",
    "\n",
    "No toolchain\n",
    "\n",
    "* Add -fopenmp to compiler command line\n",
    "  * generate code from pragmas directives\n",
    "  * links to libopenmp\n",
    "* `#include “omp.h”` to import symbols into your source code\n",
    "\n",
    "Example compile command lines:\n",
    "  * gcc -fopenmp -O3 program.c (gcc)\n",
    "  * gcc -Xpreprocessor -fopenmp -O3 -lomp program.c (clang MacOSX)\n",
    "\n",
    "#### (Aside) Compiler Optimization\n",
    "\n",
    "All compilers, including gcc/g++, have optimization flags that must be set to get good performance.\n",
    "\n",
    "Optimization level –O*:\n",
    "  * -O0 (default) = Reduce compilation time and make debugging produce the expected results.\n",
    "  * -O1 = simple optimizations that don’t take a lot of compile time\n",
    "  * -O2 = rewrite loops, follow jump pointers, inline small functions, no time/space tradeoffs\n",
    "  * -O3 = vectorize, inline functions, branch prediction\n",
    "\n",
    "When debugging, you want to use -O0 so the code makes sense.\n",
    "\n",
    "For performance, -O3 to vectorize code to processors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Model and Hardware\n",
    "\n",
    "OpenMP is a parallel programming environment that:\n",
    "  * creates _threads_ that run on mutliple processor cores\n",
    "\n",
    "#### Shared Memory\n",
    "\n",
    "* Coherent read/write to common memory from multiple cores/processors/(machines)\n",
    "  * Coherent = repeatable read, read last write, ….\n",
    "  * Abstraction that there is a single memory for all processors\n",
    "  * Data sharing by reading/writing to memory\n",
    "* Hardware that provides this abstraction are called shared memory architectures (typically in a “single machine”)\n",
    "  * Even if there are different physical memories\n",
    "  * Non-Uniform memory architectures (NUMA) are typical today\n",
    "    * with different latency and throughput from cores to memory locations\n",
    "    * but the appearance (semantics) of a single, unified memory\n",
    "    \n",
    "<img src=\"https://computing.llnl.gov/tutorials/parallel_comp/images/numa.gif\" width=\"512\" title=\"Non-Uniform Memory Architecture\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenMP onto Accelerators\n",
    "\n",
    "Accelerators are co-processors (not the main CPU)\n",
    "  * Offload compute-intensive tasks onto specialized hardware\n",
    "  * Power dense and cheaper when compared with main CPU\n",
    "  * Often limited programming models or compute capabilities\n",
    "\n",
    "Xeon-Phi is the Intel accelerator architecture\n",
    "  * compares well with GPU on price, memory throughput, and compute\n",
    "  * large number of x86 compatible cores\n",
    "  * programmable via OpenMP with \"offload\" compiler directives\n",
    "  \n",
    "Accelerators are ubiquitous in top computer architectures\n",
    "  * most machines use GPUs\n",
    "  * Intel Mic on Tianhe-2 (#4 on Top500 as of June 2018)\n",
    "  \n",
    "Intel MIC slightly more expensive..,...much easier to program.\n",
    "\n",
    "<img src=\"https://www.extremetech.com/wp-content/uploads/2014/11/XeonPhiFeature-640x353.jpg\" width=\"512\" title=\"Xeon Phi\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
