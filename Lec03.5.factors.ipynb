{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factors against Parallelism\n",
    "\n",
    "* Startup costs associated with initiating (or tearing down) processes\n",
    "  * May often overwhelm actual processing time (rendering ||ism useless)\n",
    "  * Involve thread/process creation, data movement\n",
    "* Interference: slowdown resulting from multiple processors accessing shared resources\n",
    "  * Resources: memory, I/O, system bus, sub-processors\n",
    "  * Software synchronization: locks, latches, mutexes\n",
    "  * Hardware synchronization: cache faults, interrupts\n",
    "* Skew: when breaking a single task into many smaller tasks, not all tasks may be the same size\n",
    "  * Not all tasks finish at the same time\n",
    "  \n",
    "The course will cover all of these in specific details. At this time, you should understand these three factors by visual example. I used to teach this unit by analogy with the real world examples. This was cute, but confusing. I've left this material at the end. The visual examples are boring, but concise and accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Startup Costs\n",
    "\n",
    "The NERSC tutorial on OpenMP (our next unit) draws a schematic of a parallel program as consisting of parallel execution parts and serial parts. \n",
    "\n",
    "<img src=\"https://docs.nersc.gov/development/programming-models/openmp/OpenMPforkjoin.png\" width=\"500\" title=\"https://docs.nersc.gov/development/programming-models/openmp/OpenMPforkjoin.png\" />\n",
    "\n",
    "The portions of the progam in the parallel region during which the threads are not running fully in parallel are the startup costs (or teardown costs). The dashed lines indicate periods of time in which the program is not running in parallel. The solid lines indicate times when the program is running in parallel.\n",
    "\n",
    "During the sequential parts, one would not expect parallelism. This diagram shows that even during the parallel parts, one might not realize perfect parallelism.\n",
    "\n",
    "Examples of startup costs include:\n",
    "  * operating system overheads: creation of threads of processes\n",
    "  * data access: loading or copying data to the parallel workers\n",
    "  \n",
    "Similarly we may experience teardown costs in closing parallel contexts:\n",
    "  * operating system cleaning up thread/process state\n",
    "  * copying partial results from parallel computation to memory or storage\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interference\n",
    "\n",
    "The paper [Thiffault et al. Dynamic instrumentation of large-scale MPI and OpenMP applications](http://cs.umanitoba.ca/pub/IPDPS03/DATA/16_04_089.PDF) shows a timeline of parallel computation of a neutron-transfer physics code. The image shows multiple processes awaiting on data to be transferred from other nodes and threads within each process executing intermittently.   \n",
    "\n",
    "<img src=\"./images/sweep3d.png\" width=\"500\" /> \n",
    "\n",
    "Interference arises when parallel execution contexts have to wait on each other. This manifests in multiple ways:\n",
    "  * communicating processes waiting on messages\n",
    "  * processes waiting on shared resources\n",
    "      * these can be sofware constructs, such as locks\n",
    "      * or they can be hardware constructs, such as cache lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skew\n",
    "\n",
    "Skew arises when execution cannot advance until all jobs complete. This problem is most acute when one decomposes a problem into independent parts that are of different sizes.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Waiting for long jobs to complete when all the short jobs are done is known as a problem of \"stragglers\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiple Factors\n",
    "\n",
    "Many computational frameworks operate in a manner in which they:\n",
    "  * launch a bunch of parallel jobs (startup)\n",
    "  * wait for all jobs to complete (skew)\n",
    "  * integrate/coordinate the parts (interference)\n",
    "  * restart a bunch of new parallel jobs -- REPEAT!\n",
    "  \n",
    "  \n",
    "In this case\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/ee/Bsp.wiki.fig1.svg/540px-Bsp.wiki.fig1.svg.png\" width=\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In Computers: Real things that Degrade Parllelism\n",
    "\n",
    "* I/O (memory and storage)\n",
    "  * may be startup (load data before computation)\n",
    "  * may be interference (awaiting data transfer between parallel tasks)\n",
    "  * may be skew (await I/O completion of one task)\n",
    "* Network communication\n",
    "    * similar to I/O but always involves communication\n",
    "* Failures—particularly slow/failed processes (often skew)\n",
    "\n",
    "The HPC community focuses on communication (among processes) as the major source of slowdown.  This is a traditional (I/O and networking) view.\n",
    "\n",
    "### Communication\n",
    "\n",
    "* Parallel computation proceeds in phases\n",
    "  * Compute (evaluate data that you have locally)\n",
    "* Communicate (exchange data among compute tasks).  Performance is governed by:\n",
    "  * Latency: fixed cost to send a message\n",
    "  * Round trip time (speed of light and switching costs)\n",
    "* Bandwidth: marginal cost to send a message\n",
    "  * Link capacity\n",
    "* Latency dominates small messages and bandwidth dominates large.\n",
    "  * It is lmost always better to increase message size for performance, but difficult to achieve in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mitigation: Overlapped I/O and Computation\n",
    "\n",
    "(I/O or messaging) and computation that occur in parallel are overlapped\n",
    "\n",
    "<img src=\"./images/overlap.png\" width=\"512\" title=\"Unknown source\" />\n",
    "\n",
    "* _Concept_: When performing a slow operation\n",
    "  * do the slow operation asynchronously\n",
    "  * do useful work with processor while waiting\n",
    "* Overlap is one of the simplest and most important forms of asynchronous execution\n",
    "  * identify independent tasks and do in parallel\n",
    "  * reorder I/O to initiate as early as possible and wait as late as possible\n",
    "  * while computing at the same time\n",
    "  \n",
    "I've built a toy example to demonstrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute \n",
    "def factorial(number):  \n",
    "    f = 1\n",
    "    for i in range(2, number+1):\n",
    "        f *= i\n",
    "    return f\n",
    " \n",
    "# synchronous I/O\n",
    "def io_from_devnull(number):\n",
    "    with open(\"/dev/null\", \"rb\") as fh:\n",
    "        for i in range(number):\n",
    "            fh.read(1)\n",
    "    return number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.8 ms ± 3.22 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "11.6 ms ± 91.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit factorial(10000)\n",
    "%timeit io_from_devnull(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 ms ± 931 µs per loop (mean ± std. dev. of 7 runs, 20 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 20 \n",
    "factorial(10000)\n",
    "io_from_devnull(30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.5 ms ± 1.9 ms per loop (mean ± std. dev. of 7 runs, 20 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 20\n",
    "\n",
    "from multiprocessing import Process\n",
    "p1 = Process(target=factorial, args=(10000,))\n",
    "p2 = Process(target=io_from_devnull, args=(30000,))\n",
    "p1.start()\n",
    "p2.start() \n",
    "p1.join()\n",
    "p2.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Factors Conclusions\n",
    "\n",
    "* Factors against parallelism are the most important design consideration.\n",
    "  * This is the non-optimized part in Amdahl’s law\n",
    "* Performance visualization tools are a valuable part of understanding and debugging parallelism.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
