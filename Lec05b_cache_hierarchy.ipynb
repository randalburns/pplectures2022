{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Cache Hierarchy\n",
    "\n",
    "* Memory is an abstraction\n",
    "  * looks to processor like a 1-d adress space of data locations\n",
    "  * uniform access from all cores/processors\n",
    "*  Actually a steep, hieararchy of cache in which different levels have different:\n",
    "  * Performance\n",
    "  * Capacity\n",
    "  * Sharing\n",
    "  \n",
    "<img src=\"https://sites.google.com/site/cachememory2011/_/rsrc/1311628836036/memory-hierarchy/hei.png\" width=512 title=\"Cache Hierarchy\" />\n",
    "\n",
    "* Caches are a place to store a smaller amount of data the is frequently/recently used to make data access faster.\n",
    "  * Processor caches (on chip) cache for memory.  Managed by hardware.\n",
    "  * Memory (DRAM) is a cache for pages from disk.  Managed by a storage system (database, file system).\n",
    "  * Management refers to the process of loading and evicting the contents in response to workload.\n",
    "  \n",
    "### The Hierarchy\n",
    "\n",
    "<img src=\"http://www.imexresearch.com/newsletters/images/201009_SSDImages/20100913_SSD_0000.png\" width=512 title=\"IMEX Data on Latency and Cost\" />\n",
    "\n",
    "<img src=\"https://eda360insider.files.wordpress.com/2012/05/wegener-1.gif?w=1400\" width=512 title=\"Cache latency and granularity\" />\n",
    "\n",
    "### Latency\n",
    "\n",
    "Delays (in clock cycles) to different levels in the cache hierarchy for an i7 (Nehalem)\n",
    " * $1$ cycle to registers (private to each core)\n",
    " * $1$ cycle to L1 (private to each core)\n",
    " * $4$ cycles to L2 (private to each core)\n",
    " * $35$ cycles to L3 (shared by cores)\n",
    " * $145$ cycles to memory (shared by processors)\n",
    " * $10^5$ cycles to NVRAM\n",
    " * $10^7$ cycles to disk\n",
    "\n",
    "_Data Loading_: New data that has not been used yet must come from SSD or disk.  Can be very slow.\n",
    "\n",
    "_Data Sharing_: When two threads need to share data, they incur the cost of transferring data through the fastest shared cache.\n",
    "  * 2 cores on the same processor take 70 cycles (35 to write to L3 and 35 to read from L3)\n",
    "  * 2 processors take 290 cycles\n",
    "Sharing dyanmics result in _interference_ between processes that share data in OpenMP and threads.  This is the major source for lost parallelism in these programming models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processor Caching Concepts\n",
    "\n",
    "The memory system should be thought of a a vectorized parallel system.  Whenever you \n",
    "get data, you get many words of data.  To get good memory throughput, you must \n",
    "use all that data.  Most important to understanding cache performance are:\n",
    "* __cache line__: data are moved among levels in the cache one line at a time\n",
    "  * as small as 64 bytes (L1 or L2)\n",
    "  * think of each load as the parallel load of an entire line\n",
    "  * good parallel programs will use as 64 bytes\n",
    "* __unified__: refers to whether or not the cache is shared (among cores or processors)\n",
    "\n",
    "Other concepts that don't matter as much.\n",
    "* __inclusive vs exclusive__: has implications for hardware management policies.  We don't care.\n",
    "  * __inclusive__: data in higher level caches are also in lower level caches\n",
    "  * __exclusive__: data in higher level caches are not in lower level caches\n",
    "* __associativity__: the number of hardware locations that a cache line can go into\n",
    "  * important for HW design.  We typically don't care until we get to CUDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So What\n",
    "\n",
    "* You can’t just access memory\n",
    "  * Different memory access patterns result in 50x performance differences for the same computation\n",
    "* Worry about:\n",
    "  * Parallelism: am I using all the data in a cache line\n",
    "    * To access a single byte, one must load a whole line\n",
    "    * Sequential access to memory is always parallel!\n",
    "  * Sharing/reuse: is my program referencing data in the cache more than once?  At what levels?\n",
    "\n",
    "Good memory access patterns are __aligned, sequential__ and __coalesced__.\n",
    "  * Aligned – access range starts/ends on cache line boundaries\n",
    "  * Sequential – a continuous range of bytes\n",
    "  * Coalesced – combine multiple small accesses into fewer large accesses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Neat Experiment\n",
    "\n",
    "For an array of different sizes, loop over the array repeatedly acessing every 128th byte on a Power 7 processor.\n",
    "\n",
    "<img src=\"https://www.ibm.com/developerworks/community/wikis/form/anonymous/api/wiki/26579cc3-66fe-42b8-baf9-1fcc88445848/page/523bd8d0-b51c-4c19-94ef-b1674779b5d8/attachment/ff9ae87f-2a1d-43d5-9c6d-916426cb4fc2/media/lat_mem_rd-1st.png?preventCache=1466696220189\" width=512 title=\"lat_mem_rd\" />\n",
    "\n",
    "The results show:\n",
    "  * arrays are accessed from the smallest cache that contains the entire array\n",
    "  * there are steep performance cliffs between each of the hardware levels\n",
    "  * main memory has a more complex transition\n",
    "    * it is software managed with more complex policies\n",
    "    * for large arrays, performance matches latency\n",
    "    \n",
    "__Conclusion__: the exact same code at different sizes can have >20x performance differences.\n",
    "  * you have to understand the cache hierarchy and reason about where your code runs to write fast code.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
