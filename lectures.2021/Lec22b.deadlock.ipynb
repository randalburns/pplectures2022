{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MPI Messaging and Deadlock\n",
    "\n",
    "### Point-to-Point Messaging\n",
    "\n",
    "* This is the fundamental operation in MPI\n",
    "* Send a message from one process to another\n",
    "  * Blocking I/O\n",
    "  * Blocking provides built in synchronization\n",
    "  * Blocking can lead to deadlock\n",
    "* Send and receive, let's do an example in `nodeadlock.c`\n",
    "  * this program passes a \"token\" around a ring of processes\n",
    "  * ring defined by the program\n",
    "  * **NOTE** this is a flawed program.  The correct implementation is `passitforward.c`\n",
    "  \n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/3/36/MPI_Ring_topology.png\" width=312 />\n",
    "\n",
    "  \n",
    "* What's in a message?\n",
    "  * first three arguments specify content\n",
    "  * then location (receive from or send to)\n",
    "  * message metadata\n",
    "  * and a \"communicator\" which is a virtual network\n",
    "  \n",
    "```c\n",
    "int MPI_Send ( \n",
    "  \tvoid* sendbuf, \n",
    "\tint count, \n",
    "\tMPI_Datatype datatype,\n",
    "\tint dest,\n",
    "\tint tag,\n",
    "\tMPI_Comm comm )\n",
    "    \n",
    "int MPI_Recv ( \n",
    "  \tvoid* recvbuf, \n",
    "\tint count, \n",
    "\tMPI_Datatype datatype,\n",
    "\tint source,\n",
    "\t. . . )\n",
    "```\n",
    "\n",
    "* All MPI data are arrays\n",
    "  * Where is it? `void *`\n",
    "  * How many? `count`\n",
    "  * What type? `MPI_Datatype`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deadlock\n",
    "\n",
    "In concurrent computing, a deadlock is a state in which each member of a group is waiting for another member, including itself, to take action, such as sending a message or more commonly releasing a lock.\"\n",
    "\n",
    "* Conditions for deadlock\n",
    "  * Mutual exclusion\n",
    "  * Hold and wait\n",
    "  * No preemption\n",
    "  * Circular wait\n",
    "  \n",
    "The simplest deadlock occurs with two processes and 2 resources.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/28/Process_deadlock.svg/440px-Process_deadlock.svg.png\" width=256 />\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/d/df/Two_processes%2C_two_resources.gif\" width=256 />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the gif, the deadlock is resolved by restarting the top process.  This violates the \"hold and wait\" principle.\n",
    "\n",
    "In MPI, programmers design their own messaging protocols.  We note that:\n",
    "  * MPI messaging is synchronous and blocking\n",
    "  * i.e. the caller waits on the message to be delivered prior to returning\n",
    "So why didn't nodeadlock.c produce a deadlock?\n",
    "\n",
    "Examples:\n",
    "* `deadlock.c` shows the flaw in `nodeadlock.c`\n",
    "  * forces the send to be synchronous.\n",
    "* `passitforward.c` correct implementation with _paired send and receive_\n",
    "\n",
    "### ON `MPI_Send`\n",
    "\n",
    "* MPI has the option to buffer message when there is memory available\n",
    "   * So `MPI_Send` can return immediately\n",
    "* MPI is not required to buffer messages\n",
    "    * and does not do so when memory is limited\n",
    "* This leads to horrible errors\n",
    "  * Because semantics/correctness change based on job configuration.\n",
    "  * You develop program on small cluster\n",
    "      * Has plenty of memory for small instances\n",
    "      * Messages get buffered which hides unsafe (deadlock) messaging protocol\n",
    "  * You launch code on big cluster with big instance\n",
    "      * More memory consumption means that MPI canâ€™t buffer messages\n",
    "      * Your code deadlocks\n",
    "\n",
    "_Best practice_: test messaging protocols with synchronous sends `MPI_Ssend`, deploy code with `MPI_Send`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messaging Topologies\n",
    "\n",
    "There are many strategies for breaking deadlock.\n",
    "\n",
    "### One Receiver\n",
    "\n",
    "For linear orderings and rings\n",
    "* Simplest and sufficient: (n-1) send/receive, 1 receive/send\n",
    "* Correct for any connected topology, any number of nodes\n",
    "```c\n",
    "// Example for a ring\n",
    "next =  ( ID + 1 ) % num_procs;\n",
    "prev = ID == 0 ? num_procs -1 : ID-1; \n",
    "if ( ID==0 )\n",
    "    receive(source=prev);\n",
    "    send(target=next);\n",
    "} else  {  \n",
    "    send(target=next);\n",
    "    receive(source=prev);\n",
    "}\n",
    "```\n",
    "This discipline is used by the `MPI_send_receive()` call.  It's always correct, but creates a serial dependency among messages.  The following chart shows the outcome of send calls (yellow) and receive calls (blue)\n",
    "\n",
    "<img src=\"http://pages.tacc.utexas.edu/~eijkhout/pcse/html/graphics/linear-serial.jpg\" width=\"400\" />\n",
    "\n",
    "### Paired Sends and Receives\n",
    "\n",
    "Order/pair sends and receives to avoid deadlocks (see `passitforward.c`)\n",
    " * More parallel alternative\n",
    " * Break two-way communication into two phases in which half of the nodes send in phase one and receive in phase two and vice version\n",
    "\n",
    "<img src=\"./images/pairedsr.png\" width=512 />\n",
    "\n",
    "#### More complex communication topologies?\n",
    "\n",
    "How would we design a messaging discipline for a continuous/cyclic 2-d grid\n",
    "of processes (as in our Game of Life assignment)?\n",
    "  * That want to send to up/down/left/right neighbors?\n",
    "  * That want to send to diagonal neighbors also?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
